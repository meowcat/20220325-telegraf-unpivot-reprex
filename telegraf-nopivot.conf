# Global tags can be specified here in key="value" format.
[global_tags]
  # dc = "us-east-1" # will tag all metrics with dc=us-east-1
  # rack = "1a"
  ## Environment variables can be used as tags, and throughout the config file
  # user = "$USER"

# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "3s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 1000

  ## Maximum number of unwritten metrics per output.  Increasing this value
  ## allows for longer periods of output downtime without dropping metrics at the
  ## cost of higher maximum memory usage.
  metric_buffer_limit = 100000

  collection_jitter = "0s"

  flush_interval = "10s"

  flush_jitter = "0s"
  precision = ""
  ## Log at debug level.
  debug = false
  ## Name of the file to be logged to when using the "file" logtarget.  If set to
  ## the empty string then logs are written to stderr.
  logfile = ""
  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false

#Send telegraf metrics to file(s)
[[outputs.file]]
  ## Files to write to, "stdout" is a specially handled file.
  files = ["/opt/telegraf/metrics.out"]
  data_format = "influx"
  use_batch_format = false
  rotation_interval = "0"
  rotation_max_size = "0MB"
  rotation_max_archives = 5


[[inputs.directory_monitor]]

  name_override = "mymetric"
  directory = "/data/in"
  #
  ## The directory to move finished files to.
  finished_directory = "/data/out"
  error_directory = "/data/err"
  files_to_monitor = [".*\\.csv"]
  directory_duration_threshold = "10s"
  max_buffered_metrics = 5000
  file_queue_size = 100000
  

  data_format = "csv"
  csv_delimiter = "\t"
  csv_header_row_count = 0
  #csv_skip_rows = 1
  csv_column_names = [
    "ts",
    "date",
    "C",
    "D",
    "E",
    "F",
    "G",
    "H",
    "I",
    "J",
    "K",
    "L",
    "M",
    "N",
    "O",
    "P",
    "Q",
    "R",
    "S",
    "T",
    "U",
    "V",
    "W",
    "X",
    "Y",
    "Z",
    "AA",
    "AB",
    "AC",
    "AD",
    "AE",
    "AF",
    "AG",
    "AH",
    "AI",
    "AJ",
    "AK",
    "AL",
    "AM",
    "AN",
    "AO",
    "AP",
    "AQ",
    "AR",
    "AS",
    "AT",
    "AU"
  ]
  csv_timestamp_column = "date"
  csv_timestamp_format = "2006-01-02 15:04:05"
  file_tag = "machine"